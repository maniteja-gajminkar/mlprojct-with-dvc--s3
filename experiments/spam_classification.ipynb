{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c4b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9661508704061895\n",
      "Precision:  0.9327731092436975\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.9274661508704062\n",
      "Precision:  1.0\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.9655172413793104\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.9361702127659575\n",
      "Precision:  0.9\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9622823984526112\n",
      "Precision:  0.9541284403669725\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.971953578336557\n",
      "Precision:  0.943089430894309\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.9235976789168279\n",
      "Precision:  0.8734177215189873\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# üì• DATA INGESTION\n",
    "# ====================================\n",
    "# Importing necessary libraries\n",
    "import numpy as np        # For numerical operations\n",
    "import pandas as pd       # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing WordCloud for text visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords    # For stopwords\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('stopwords')   # Downloading stopwords data\n",
    "nltk.download('punkt')       # Downloading tokenizer data\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('spam.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "# ====================================\n",
    "# üßπ DATA PREPROCESSING\n",
    "# ====================================\n",
    "\n",
    "# Dropping columns\n",
    "df.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\n",
    "df.head()\n",
    "\n",
    "# Rename the columns name\n",
    "df.rename(columns = {'v1': 'target', 'v2': 'text'}, inplace = True)\n",
    "df.head()\n",
    "\n",
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "df.head()\n",
    "\n",
    "# Check duplicate values\n",
    "df.duplicated().sum()\n",
    "len(df)\n",
    "\n",
    "# Remove Duplicates\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "len(df)\n",
    "\n",
    "# ====================================\n",
    "# üß† FEATURE ENGINEERING\n",
    "# ====================================\n",
    "\n",
    "# Importing the Porter Stemmer for text stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Lowercase transformation and text preprocessing function\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "\n",
    "transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')\n",
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df.head()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfid = TfidfVectorizer(max_features = 500)\n",
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values\n",
    "\n",
    "# ====================================\n",
    "# üß™ MODEL TRAIN-TEST SPLIT\n",
    "# ====================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)\n",
    "\n",
    "# ====================================\n",
    "# üèóÔ∏è MODEL TRAINING\n",
    "# ====================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)\n",
    "\n",
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "}\n",
    "\n",
    "# ====================================\n",
    "# üìä MODEL EVALUATION\n",
    "# ====================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy , precision\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name , clfs in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
